<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Recovering SLAM Tracking Lost by Trifocal Pose Estimation using GPU-HC++</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Recovering SLAM Tracking Lost by Trifocal Pose Estimation using GPU-HC++</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Chiang-Heng Chien (Brown University), Ahmad Abdelfattah (University of Tennessee, Knoxville), Benjamin Kimia (Brown University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_1020/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_1020/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_1020/video.mp4" role="button">Video</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_1020/supplementary1020.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>Camera pose tracking in visual odometry (VO) or simultaneous localization and mapping (SLAM) is generally robust when there is sufficient texture in images. There are, however, a small percentage of examples where the process fails due to textureless scenes. In this case, modern VO/SLAM typically relies on finding 2D bifocal feature matches whose corresponding 3D points exist in the map to recover from failure. This is, however, not very helpful, as ruling out 2D feature matches whose corresponding 3D points do not exist leaves only minor amount of matches available for pose estimation, a catastrophic situation when the texture is already insufficient in images. 
This paper proposes integrating modern VO/SLAM with trifocal pose estimation for resolving tracking failure. By acquiring two history images from the covisible graph in conjunction with the current image, trifocal poses can be found from triplet 2D oriented point matches, {\em e.g.}, SIFT or ORB, where one is associated with a 3D point in space.
In addition, existing trifocal pose estimation solver are computationally too expensive to be used in a practical setting, particularly under a RANSAC scheme for robust estimation. This paper thus propose an enhanced GPU-based homotopy continuation solver (GPU-HC), called GPU-HC++, whose performance is significantly improved over GPU-HC. 
We show that integrating PLP-SLAM and ORB-SLAM3 with the proposed approach on challenging sequences of TUM-RGBD and EuRoC datasets substantially increases the success rate of tracking failure recovery without the cost of losing significant runtime.<br><br><h2>Video</h2><center><iframe height="540" width="960" style="max-width:100%;max-height:100%;" src="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_1020/video.mp4" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></center><br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Chien_2024_BMVC,
author    = {Chiang-Heng Chien and Ahmad Abdelfattah and Benjamin Kimia},
title     = {Recovering SLAM Tracking Lost by Trifocal Pose Estimation using GPU-HC++},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/1020.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>