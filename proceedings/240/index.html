<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>SAM Helps SSL: Mask-guided Attention Bias for Self-supervised Learning</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>SAM Helps SSL: Mask-guided Attention Bias for Self-supervised Learning</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Kensuke Taguchi (Kyocera Corporation), Takehiko Kawai (Kyocera Corporation), Wataru Imaeda (Kyocera Corporation), Hironobu Fujiyoshi (DENSO CORPORATION)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/video.mp4" role="button">Video</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/supplementary240.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>The vision transformer(ViT) and self-supervised learning(SSL) are key technologies for accelerating data scalability, contributing to the emergence of a foundation model in computer vision.
  In this paper, we focus on the potential of masks generated by the Segment Anything Model(SAM), a foundation model for image segmentation, and propose a novel method for SSL, named ``mask-guided attention bias''. 
   Mask-guided attention bias is designed to encode SAM-generated masks, which are spatially and semantically decomposed information about an image. It is applied to the self-attention of ViT as guidance for an SSL process. Since self-attention can capture a wide range of spatial dependencies, mask-guided attention bias effectively adds spatial and semantic guidance to various forms of SSL, thus improving the decodability and labeling efficiency of SSL representations.
  We show that our method improves the accuracy of linear probing, few-shot learning, and fine-tuning in general. In particular, our method achieves 81.3\% linear probing accuracy (outperforming vanilla MAE by 3.2\%) and 89.5\% fine-tune accuracy (outperforming vanilla DINO by 0.4\%) on ImageNet100.<br><br><h2>Video</h2><center><iframe height="540" width="960" style="max-width:100%;max-height:100%;" src="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_240/video.mp4" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></center><br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Taguchi_2024_BMVC,
author    = {Kensuke Taguchi and Takehiko Kawai and Wataru Imaeda and Hironobu Fujiyoshi},
title     = {SAM Helps SSL: Mask-guided Attention Bias for Self-supervised Learning},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0240.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p></body></html>