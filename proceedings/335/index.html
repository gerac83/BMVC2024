<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Hao Chen (Department of Computer Science and Engineering, The Chinese University of Hong Kong), Jiaze Wang (The Chinese University of Hong Kong), Ziyu Guo (Department of Computer Science and Engineering, The Chinese University of Hong Kong), Jinpeng Li (The Chinese University of Hong Kong), Donghao Zhou (The Chinese University of Hong Kong), Bian Wu (Zhejiang University), Chenyong Guan (Gudsen Technology Co. Ltd), Guangyong Chen (Zhejiang Lab), Pheng-Ann Heng (The Chinese University of Hong Kong)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_335/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_335/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_335/video.mp4" role="button">Video (Right click to download)</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_335/supplementrary335.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>Sign language recognition (SLR) plays a vital role in facilitating communication for the hearing-impaired community. A significant challenge in SLR arises from its weakly supervised nature, where each entire video is annotated with a sequence of glosses. This makes it particularly difficult to accurately identify the corresponding gloss for specific video segments. To address this challenge, we present SignVTCL, a multi-modal continuous sign language recognition framework enhanced by visual-textual contrastive learning, which leverages the full potential of multi-modal data and the generalization ability of language model. First, SignVTCL consolidates multi-modal data to train a unified visual feature extractor, resulting in more robust visual representations. Subsequently, it employs a visual-textual alignment approach that integrates gloss-level and sentence-level alignments, establishing precise correspondences between visual and textual features to enhance SLR accuracy. Experimental results conducted on three datasets, Phoenix-2014, Phoenix-2014T, and CSL-Daily, demonstrate that SignVTCL achieves state-of-the-art results compared with previous methods. Project page: https://jiazewang.com/projects/signvtcl.html.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Chen_2024_BMVC,
author    = {Hao Chen and Jiaze Wang and Ziyu Guo and Jinpeng Li and Donghao Zhou and Bian Wu and Chenyong Guan and Guangyong Chen and Pheng-Ann Heng},
title     = {SignVTCL: Multi-Modal Continuous Sign Language Recognition Enhanced by Visual-Textual Contrastive Learning},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0335.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>