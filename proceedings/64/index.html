<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Multi-Modal Information Bottleneck Attribution with Cross-Attention Guidance</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Multi-Modal Information Bottleneck Attribution with Cross-Attention Guidance</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Pauline Bourigault (Imperial College London), Emmanuelle Bourigault (University of Oxford), Danilo Mandic (Imperial College London)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/video.mp4" role="button">Video</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/supplementary64.pdf" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>For the advancement of interpretable machine learning, particularly in the intersection of vision and language, ensuring transparency and comprehensibility in model decisions is crucial. This work introduces a novel enhancement to the Multi-modal Information Bottleneck (M2IB) attribution method by integrating cross-attention mechanisms, termed Cross-Attention M2IB (CA-M2IB). This targets the core challenge of improving the interpretability of vision-language pretrained models, such as CLIP, by fostering more discerning and relevant latent representations. CA-M2IB filters and retains essential information across modalities, leveraging cross-attention to dynamically focus on pertinent visual and textual features for any given context. Through evaluations using CLIP as an example, CA-M2IB demonstrates improvements in attribution accuracy and interpretability over existing attribution methods, including gradient-based, perturbation-based, attention-based, and the information-theoretic M2IB methods. By providing a more nuanced understanding of model decisions, CA-M2IB contributes to offer a promising avenue for deploying vision-language models in critical domains such as healthcare.<br><br><h2>Video</h2><center><iframe height="540" width="960" style="max-width:100%;max-height:100%;" src="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_64/video.mp4" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></center><br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Bourigault_2024_BMVC,
author    = {Pauline Bourigault and Emmanuelle Bourigault and Danilo Mandic},
title     = {Multi-Modal Information Bottleneck Attribution with Cross-Attention Guidance},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0064.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p></body></html>