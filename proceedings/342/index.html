<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Unsupervised Domain Adaptation for Tubular Structure Segmentation Across Different Anatomical Sources</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Unsupervised Domain Adaptation for Tubular Structure Segmentation Across Different Anatomical Sources</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Yuxiang An (University of Sydney), Dongnan Liu (University of Sydney), Weidong Cai (University of Sydney)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_342/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_342/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_342/video.mp4" role="button">Video</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_342/supplementary342.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>Unsupervised domain adaptation (UDA) aims to boost the generalization ability of deep learning networks by leveraging the unlabeled data, which is a commonly used approach in medical image analysis. However, existing UDA methods only focus on bridging the gap between the same anatomical sites, which leads to the adaptation between different anatomical sites under-explored. UDA under multi-anatomical source settings is more challenging, due to 1) the gray-scale distribution and structural distribution of images of different anatomical sources of tubular structures vary greatly, and 2) The prior knowledge contained in the labels of different anatomical sources is inconsistent. In this paper, we propose an unsupervised domain adaptation method for segmenting tubular structures across different anatomical sources. Specifically, we treat different anatomical sites as different sources. Our method first reduces the domain gap by automatically adjusting the gray-scale distribution of images in different domains using a gray-scale transformation network. Secondly, we introduce target domain noise when training the segmentation network to further improve the segmentation accuracy of the framework in the target domain. In addition, we also design a mask adjustment module for modifying the masks of the raw data in both domains to make the model pay more attention to the common features of the segmentation targets, which further improves the generalization ability of the model. Experimental results on four public datasets at two anatomical sources (eyes and cells) demonstrate the superiority of our proposed method compared with existing state-of-the-art approaches.<br><br><h2>Video</h2><center><iframe height="540" width="960" style="max-width:100%;max-height:100%;" src="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_342/video.mp4" frameborder="0" allow="encrypted-media" allowfullscreen></iframe></center><br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{An_2024_BMVC,
author    = {Yuxiang An and Dongnan Liu and Weidong Cai},
title     = {Unsupervised Domain Adaptation for Tubular Structure Segmentation Across Different Anatomical Sources},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0342.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>