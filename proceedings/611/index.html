<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>STPose: 6D object pose estimation network based on sparse attention and cross-layer connection</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>STPose: 6D object pose estimation network based on sparse attention and cross-layer connection</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Shihao Chen (Wuhan University), Xiaobing Li (Guangxi University), Keduo Yan (Guangxi University), Yong Li (Guangxi University), Dongxu Gao (University of Portsmouth)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_611/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_611/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_611/video.mp4" role="button">Video (Right click to download)</a><br></div><h2 id="abstract">Abstract</h2>The 6D object position estimation technique provides accurate and rich coordinate information for robots to grasp target objects, while implementing the algorithms of this technique in industry often requires consideration of smaller cost loss. In this paper, we propose STPose, a transformer-based position estimation network using only RGB images as input. Our network is based on PoET and proposes to reduce the computational parameters of the model with convergence efficiency by introducing a sparse attention method and an encoder cross-layer connection method. We also propose a system that enables easy and automatic implementation of labeled position estimation datasets, since no research has been done to apply this technique to the power environment. Using this system, we produce a position estimation dataset, the RCV dataset, targeting power device tools.STPose provides the best results among the currently studied algorithms on the RCV dataset and outperforms PoET (RGB-input-only Sota method) by 2.4% on the difficult YCB-V dataset. We also conduct an experimental analysis of the RCV dataset's features and difficulties. The project is available for public use at https://github.com/Agatha7k/STPose.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Chen_2024_BMVC,
author    = {Shihao Chen and Xiaobing Li and Keduo Yan and Yong Li and Dongxu Gao},
title     = {STPose: 6D object pose estimation network based on sparse attention and cross-layer connection},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0611.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>