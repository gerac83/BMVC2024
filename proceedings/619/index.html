<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Prompt-guided Multi-modal contrastive learning for Cross-compression-rate Deepfake Detection</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Prompt-guided Multi-modal contrastive learning for Cross-compression-rate Deepfake Detection</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Ching-Yi Lai (National Tsinghua University), Chiou-ting Hsu (National Tsing Hua University), Chih-Chung Hsu (National Yang Ming Chiao Tung University), Chia-Wen Lin (National Tsing Hua University)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_619/paper.pdf" role="button">PDF</a><br></div><h2 id="abstract">Abstract</h2>In deepfake detection, diverse compression methods employed by social media platforms pose significant challenges due to varying compression rates. These variations hinder the generalization of deepfake detectors across different compression rates, termed cross-compression-rate (CCR) scenario. While existing models demonstrate robustness in cross-dataset evaluation, they often overlook the CCR scenario, which is crucial for ensuring broader applicability in real-world applications. Therefore, we introduce a novel Contrastive Physio-inspired Multi-modalities with Language guidance (CPML) framework for robust CCR deepfake detection. Our approach co-maps remote photoplethysmography (rPPG) signals and facial landmark dynamics into a common latent feature space and then aligns with a set of class prompt-guided in language semantics (e.g., real and fake classes). Specifically, we propose the Cross-Quality Similarity Learning (CQSL) strategy to learn the similarities in the rPPG signals under the variations of visual qualities. Moreover, we utilize a pre-trained vision-language model as our text encoder and propose the Cross-Modality Consistency Learning (CMCL) to pair-wisely align the multi-modal features with the textual features of the corresponding class prompts. Our extensive experiments demonstrate that the proposed achieves superior performance on both seen and unseen manipulation types and datasets, and provide a benchmark for CCR
scenarios.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Lai_2024_BMVC,
author    = {Ching-Yi Lai and Chiou-ting Hsu and Chih-Chung Hsu and Chia-Wen Lin},
title     = {Prompt-guided Multi-modal contrastive learning for Cross-compression-rate Deepfake Detection},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0619.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>