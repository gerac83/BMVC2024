<!DOCTYPE html><html lang="en-US"><head><meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" /><title>Complete the Feature Space: Diffusion-Based Fictional ID Generation for Face Recognition</title><link rel="stylesheet" href="../assets/css/style.css"><link rel="icon" type="image/png" sizes="32x32" href="/assets/favicon/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/favicon/favicon-16x16.png"></head><body><div class="wrapper"><section><center><a href="../"><img src="../images/bmvc-logo.png" width="800" class="figure-img img-responsive center-block"></a><br /><br /></center><h2 class="project-name" style="font-weight:normal; font-size: 167%;" align="center"><style>body { background-color: white !important; color: black !important; }</style>Complete the Feature Space: Diffusion-Based Fictional ID Generation for Face Recognition</h2><br><h5 style="font-weight:normal; font-size: 1.25em;" align="center"><autocolor><h5 style="font-weight:normal; color: black;" align="center">Myeong-Yeon Yi (Seoul National University), DongJae Lee (KAIST), Naeun Ko (Naver corporation), Yonghyun Jeong (NAVER), Sang-goo Lee (Seoul National University), Seunggyu Chang (NAVER Cloud)</h5></autocolor></h5><h5 style="font-weight:normal; color: black;" align="center"><a href="https://bmvc2024.org" target="_blank" style="color: black;"><i>The 35<sup>th</sup> British Machine Vision Conference</i></a></h5><div class="cta"><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_323/paper.pdf" role="button">PDF</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_323/poster.pdf" role="button">Poster</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_323/video.mp4" role="button">Video (Right click to download)</a><a href="https://bmva-archive.org.uk/bmvc/2024/papers/Paper_323/supplementary323.zip" role="button">Supplementary</a><br></div><h2 id="abstract">Abstract</h2>In deep face recognition (FR) tasks, the size and diversity of the training dataset are essential factors in improving performance. Unfortunately, crawled datasets suffer from issues such as label noise, the long-tailed problem, and privacy concerns. These problems can be solved if we can generate face images while preserving IDs in either real IDs or fictional IDs. However, previous face synthesizing approaches have limitations of requiring explicit control of facial attributes or exhibiting a lack of diversity, resulting in unsuccessful FR performance. In this paper, we propose DiffFR, a method that generates diverse face images for enhancing FR datasets within core fictional identities (IDs) by utilizing an ID-preserving diffusion model. We condition the diffusion model with a representative feature called the ID feature, to condense ID information which enables the diffusion model to generate face images in either real IDs or fictional IDs. Among the numerous fictional IDs, we select core IDs that fill the void space of FR feature space, specified as improving the inter-class sparsity. Furthermore, by leveraging the ID features to predict intra-class diversities, we ensure that intra-class diversity is duly reflected in the selection of core IDs. Our experiments demonstrate that DiffFR surpasses other synthesizing methods for FR dataset augmentation on FR benchmark sets, owing to its ability to generate datasets with a high degree of intra-class diversity and inter-class sparsity.<br><br><h2>Citation</h2><div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@inproceedings{Yi_2024_BMVC,
author    = {Myeong-Yeon Yi and DongJae Lee and Naeun Ko and Yonghyun Jeong and Sang-goo Lee and Seunggyu Chang},
title     = {Complete the Feature Space: Diffusion-Based Fictional ID Generation for Face Recognition},
booktitle = {35th British Machine Vision Conference 2024, {BMVC} 2024, Glasgow, UK, November 25-28, 2024},
publisher = {BMVA},
year      = {2024},
url       = {https://papers.bmvc2024.org/0323.pdf}
}
</code></pre></div></div><br><br><p><small style="color: black;">Copyright &copy 2024 <a href="https://britishmachinevisionassociation.github.io/" rel="noopener"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a><br>The British Machine Vision Conference is organised by <a href="https://britishmachinevisionassociation.github.io/"><black>The British Machine Vision Association and Society for Pattern Recognition</autocolor></a>. The Association is a Company limited by guarantee, No.2543446, and a non-profit-making body, registered in England and Wales as Charity No.1002307 (Registered Office: Dept. of Computer Science, Durham University, South Road, Durham, DH1 3LE, UK).</small></p><p><small><a href="https://imprint.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de" rel="noopener"><black>Imprint<black></a> | <a href="https://data-protection.mpi-klsb.mpg.de/inf/bmvc2022.mpi-inf.mpg.de?lang=en" rel="noopener"><black>Data Protection</autocolor></a></small></p></section></div></body></html>