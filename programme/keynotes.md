---
layout: default_sparse
title: Keynotes
permalink: /programme/keynotes/
index: 5
---

<div class="row justify-content-around pl-4 pr-4">

	<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
	    <div class="col-12 col-md-4 col-lg-3"><a class="anchor"></a>
	        <div class="text-center">
	            <img src="../../imgs/kn2.png" class="rounded-circle img-fluid" style="max-width: 125px;">
	            <h4 class="pt-2"><a href="https://ibug.doc.ic.ac.uk/maja/biography/">Maja Pantic</a></h4>
	            <span class=""><small>Imperial College London</small></span>
	        </div>
	    </div>
	    <div class="col-12 col-md-8 col-lg-9">
	        <div class="">
	            <h5 class="pt-1 text-center"><b>Faces, Avatars, and GenAI</b></h5>
	            <p class="text-center mb-1"><small ></small></p>
	            <p class="pb-1 mb-1">{{ person.abstract }}</p>
	            <p class="pb-2">
				<!--
				<b>Abstract: </b>
				This talk is about machine learning, computer vision and Generative AI methods developed for various human-centric AI applications, Augmented Reality and avatars generation, and about face analysis technology in general.
				<br />
				<br />
				-->
				<b>Bio: </b>Maja Pantic obtained her PhD degree in computer science in 2001 from Delft University of Technology, the Netherlands. Until 2005, she was an Assistant/ Associate Professor at Delft University of Technology. In 2006, she joined the Imperial College London, Department of Computing, UK, where she is Professor of Affective & Behavioural Computing and the Head of the iBUG group, working on machine analysis of human non-verbal behaviour. From April 2018 to April 2020, she was the Research Director of Samsung AI Research Centre in Cambridge. In April 2020, she joined Facebook as an AI Scientific Research Lead in Facebook London. Prof. Pantic is one of the world's leading experts in the research on machine understanding of human behavior including vision-based detection, tracking, and analysis of human behavioral cues like facial expressions and body gestures, and multimodal analysis of human behaviors like laughter, social signals, and affective states.  Prof. Pantic received various awards for her work including BCS Roger Needham Award, awarded annually to a UK based researcher for a distinguished research contribution in computer science, and IAPR Maria Petrou Award, awarded biannually to a living female scientist for her contributions to the field of Pattern Recognition. She is a Fellow of the UK's Royal Academy of Engineering, an IEEE Fellow and an IAPR Fellow.</p>
	        </div>
	    </div>
	</div></div>

 	<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
	    <div class="col-12 col-md-4 col-lg-3"><a class="anchor"></a>
	        <div class="text-center">
	            <img src="../../imgs/keynote1.jpg" class="rounded-circle img-fluid" style="max-width: 125px;">
	            <h4 class="pt-2"><a href="https://gkioxari.github.io/">Georgia Gkioxari</a></h4>
	            <span class=""><small>California Institute of Technology</small></span>
	        </div>
	    </div>
	    <div class="col-12 col-md-8 col-lg-9">
	        <div class="">
	            <h5 class="pt-1 text-center"><b>The Future of Recognition is 3D:<br> New Tasks, Benchmarks and Models for 3D Perception in the Wild</b></h5>
	            <p class="text-center mb-1"><small ></small></p>
	            <p class="pb-1 mb-1">{{ person.abstract }}</p>
	            <p class="pb-2"><b>Bio: </b>Georgia Gkioxari is an Assistant Professor of Computing + Mathematical Sciences at Caltech. From 2016 to 2022, she was a research scientist at FAIR. She received her PhD from UC Berkeley, where she was advised by Jitendra Malik. She did her bachelors in ECE at NTUA in Athens, Greece, where she worked with Petros Maragos. She is the recipient of the PAMI Young Researcher Award (2021). Her teammates and she received the PAMI Mark Everingham Award (2021) for the Detectron Library Suite. She was named one of 30 influential women advancing AI in 2019 by ReWork and was nominated for the Women in AI Awards in 2020 by VentureBeat.</p>
	        </div>
	    </div>
	</div></div>
	
	<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
	    <div class="col-12 col-md-4 col-lg-3"><a class="anchor"></a>
	        <div class="text-center">
	            <img src="../../imgs/keynote3.png" class="rounded-circle img-fluid" style="max-width: 125px;">
	            <h4 class="pt-2"><a href="https://www.nottingham.ac.uk/research/beacons-of-excellence/future-food/meet-the-team/michael-pound/index.aspx">Michael Pound</a></h4>
	            <span class=""><small>University of Nottingham</small></span>
	        </div>
	    </div>
	    <div class="col-12 col-md-8 col-lg-9">
	        <div class="">
	            <h5 class="pt-1 text-center"><b>How I Learned to Love Plants: <br>Efficient AI techniques for High Resolution Biological Images</b></h5>
	            <p class="text-center mb-1"><small ></small></p>
	            <p class="pb-1 mb-1">{{ person.abstract }}</p>
	            <p class="pb-2"><b>Bio: </b>Michael Pound is an Associate Professor of Computer Science at the University of Nottingham, UK. His research focuses on the development and application of computer vision approaches, often to biological images. He has been in involved in interdisciplinary research across a variety of domains, ranging from plant and medical imaging, through to engineering and physics. He is particularly interested in efficient techniques for segmentation and localisation problems in very high-resolution images, and volumetric segmentation in MRI and CT. Outside of research, he is passionate about education in computer science. He is a regular contributor to the YouTube channel Computerphile, where his videos on subjects including AI and machine learning have accumulated over 45 million views.</p>
	        </div>
	    </div>
	</div></div>

	<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
	    <div class="col-12 col-md-4 col-lg-3"><a class="anchor"></a>
	        <div class="text-center">
	            <img src="../../imgs/key5.png" class="rounded-circle img-fluid" style="max-width: 125px;">
	            <h4 class="pt-2"><a href="https://vision.in.tum.de/members/cremers">Daniel Cremers</a></h4>
	            <span class=""><small>Technical University of Munich</small></span>
	        </div>
	    </div>
	    <div class="col-12 col-md-8 col-lg-9">
	        <div class="">
	            <h5 class="pt-1 text-center"><b>3D Computer Vision for Dynamic Scene Understanding</b></h5>
	            <p class="text-center mb-1"><small ></small></p>
	            <p class="pb-1 mb-1">{{ person.abstract }}</p>
	            <p class="pb-2">
				<b>Bio: </b>Daniel Cremers received Bachelor degrees in Mathematics (1994) and Physics (1994), and a Master's degree in Theoretical Physics (1997) from the University of Heidelberg. In 2002 he obtained a PhD in Computer Science from the University of Mannheim, Germany. Subsequently he spent two years as a postdoctoral researcher at the University of California at Los Angeles (UCLA) and one year as a permanent researcher at Siemens Corporate Research in Princeton, NJ. From 2005 until 2009 he was associate professor at the University of Bonn, Germany. Since 2009 he holds the Chair of Computer Vision and Artificial Intelligence at the Technical University of Munich. His publications received several awards, including the "Best Paper of the Year 2003" (Int. Pattern Recognition Society), the "Olympus Award 2004" (now called "German Pattern Recognition Award") and the "2005 UCLA Chancellor's Award for Postdoctoral Research". For pioneering research he received a Starting Grant (2009), two Proof of Concept Grants (2014 & 2018), a Consolidator Grant (2015) and an Advanced Grant (2020) by the European Research Council. </p>
	        </div>
	    </div>
	</div></div>

</div>

