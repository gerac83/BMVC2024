---
layout: default_sparse
title: Wednesday, 27th November
permalink: /programme/wednesday/
paper: true # Hack to hide it in the header
---

<head>
  <link rel="stylesheet" href="/static/css/programmes.css">
</head>

<div class="centered">
  <a class="btn" href="/programme/programme">Schedule</a>
  <a class="btn" href="/programme/monday">Mon</a>
  <a class="btn" href="/programme/tuesday">Tue</a>
  <a class="btn btn-primary" href="/programme/wednesday">Wed</a>
  <a class="btn" href="/programme/thursday">Thu</a>
</div>

<div>
  <p><b>BMVC conference papers</b>, supplementary material and video presentations can be found at: <a href="https://gla-my.sharepoint.com/:f:/g/personal/gerardo_aragoncamarasa_glasgow_ac_uk/EhCbNLaIjqZElc787HVlDMABWUBcaWxxmBfPPuKUndeSxw?e=KGFRgb">BMVC Papers</a></p>
  <p><b>BMVC workshop papers</b> can be found at: <a href="https://gla-my.sharepoint.com/:f:/g/personal/gerardo_aragoncamarasa_glasgow_ac_uk/Enp1D-uN2wVFqjl14_2uHfgBABR4Msu6sUeH_PPuIoazHw?e=rknZMm">BMVC Workshop Papers</a></p>
</div>

<div class="tableevent">
  <details open name="events">
    <summary class="sidebyside keynote">
      <div class="">
        Keynote - Laura Sevilla
      </div>
      <div class=" rightaligned">
        09:00 - 10:00
      </div>
    </summary>
    <table>
      <tr>
        <th class="wide">09:00 - 10:00</th>
        <td><b>Title:</b> Frontiers of Video Understanding
          </p>
          <div>
            <p><b>Abstract: </b>Video Understanding is a fundamental skill of intelligent systems. From autonomous
              robots to virtual assistants, understanding the world in motion is necessary to be able to move and
              interact with it. The last few years have seen amazing improvements in Video Understanding research. Still
              there is a remarkable gap between the almost uncanny performance of models in other modalities such as
              language and still images, and the performance of video. In this talk I will discuss what I believe are
              the current barriers for video, including efficiency, a tricky relationship with language and finding the
              right tasks. For each of these topics I will discuss both my recent work on them, as well as what I
              believe are interesting directions that I hope can be inspiring for the community.</p>
            <p><a href="https://laurasevilla.me/">https://laurasevilla.me/</a></p>
          </div>
          <div class="loc">
            Room: M1
          </div>
        </td>
      </tr>
    </table>
  </details>
</div>

<div class="tableevent">
  <details name="events">
    <summary class="sidebyside poster">
      <div class="">
        Poster Sessions
      </div>
      <div class=" rightaligned">
        10:00 - 11:45 / 15:15 - 17:00
      </div>
    </summary>
    <table>
      <tr>
        <th>10:00 - 11:45</th>
        <td class="tdoral" colspan="2">
          <details>
            <summary>Papers Presented</summary>
            <div>
              <table class="responsive-table">
                <tr>
                  <td>16</td>
                  <td>
                    Region-based Entropy Separation for One-shot Test-Time
                    Adaptation
                  </td>
                  <td class="authorcell">Kodai Kawamura, Shunya Yamagami, Go Irie</td>
                </tr>
                <tr>
                  <td>28</td>
                  <td>
                    SciPostLayout: A Dataset for Layout Analysis and Layout
                    Generation of Scientific Posters
                  </td>
                  <td class="authorcell">Shohei Tanaka, Hao Wang, Yoshitaka Ushiku</td>
                </tr>
                <tr>
                  <td>31</td>
                  <td>
                    COSMo: CLIP Talks on Open-Set Multi-Target Domain Adaptation
                  </td>
                  <td class="authorcell">Munish Monga, Sachin Kumar Giroh, Ankit Jha, Mainak Singha, Biplab Banerjee, Jocelyn Chanussot</td>
                </tr>
                <tr>
                  <td>32</td>
                  <td>Can CLIP help CLIP in learning 3D?</td>
                  <td class="authorcell">Cristian Sbrolli, Matteo Matteucci</td>
                </tr>
                <tr>
                  <td>38</td>
                  <td>
                    Linear Calibration Approach to Knowledge-free Group Robust
                    Classification
                  </td>
                  <td class="authorcell">Ryota Ishizaki, Shunya Yamagami, Yuta Goto, Go Irie</td>
                </tr>
                <tr>
                  <td>70</td>
                  <td>
                    Advancing Anomaly Detection: The IDW dataset and MC algorithm
                  </td>
                  <td class="authorcell">Alexander D. J. Taylor, Jonathan James Morrison, Phillip Tregidgo, Neill D. F. Campbell</td>
                </tr>
                <tr>
                  <td>104</td>
                  <td>
                    MMPrune4U: Regularizing Multimodal Feature Distortion in Weight
                    Pruning for Deep Neural Network Compression
                  </td>
                  <td class="authorcell">Sudip Das, Kaixin Xu, Nushrat Hussain, Ziyuan Zhao, Arindam Das, Weisi Lin, Ujjwal Bhattacharya</td>
                </tr>
                <tr>
                  <td>111</td>
                  <td>
                    Projected Stochastic Gradient Descent with Quantum Annealed
                    Binary Gradients
                  </td>
                  <td class="authorcell">Maximilian Krahn, Michele Sasdelli, Frances Fengyi Yang, Vladislav Golyanik, Juho Kannala, Tat-Jun Chin, Tolga Birdal</td>
                </tr>
                <tr>
                  <td>115</td>
                  <td>Multi-modal Crowd Counting via Modal Emulation</td>
                  <td class="authorcell">Chenhao Wang, Xiaopeng Hong, Zhiheng Ma, Yupeng Wei, Yabin Wang, Xiaopeng Fan</td>
                </tr>
                <tr>
                  <td>135</td>
                  <td>
                    Acoustic-based 3D human pose estimation robust to human position
                  </td>
                  <td class="authorcell">Yusuke Oumi, Yuto Shibata, Go Irie, Akisato Kimura, Yoshimitsu Aoki, Mariko Isogawa</td>
                </tr>
                <tr>
                  <td>137</td>
                  <td>
                    InSpaceType: Dataset and Benchmark for Reconsidering Cross-Space
                    Type Performance in Indoor Monocular Depth
                  </td>
                  <td class="authorcell">Cho-Ying Wu, Quankai Gao, Chin-Cheng Hsu, Te-Lin Wu, Jing-Wen Chen, Ulrich Neumann</td>
                </tr>
                <tr>
                  <td>216</td>
                  <td>
                    Erasing Concepts from Text-to-Image Diffusion Models with
                    Few-shot Unlearning
                  </td>
                  <td class="authorcell">Masane Fuchi, Tomohiro Takagi</td>
                </tr>
                <tr>
                  <td>218</td>
                  <td>
                    RISSOLE: Parameter-efficient Diffusion Models via Block-wise
                    Generation and Retrieval-Guidance
                  </td>
                  <td class="authorcell">Avideep Mukherjee, Soumya Banerjee, Piyush Rai, Vinay P. Namboodiri</td>
                </tr>
                <tr>
                  <td>228</td>
                  <td>
                    Learning Scene-Goal-Aware Motion Representation for Trajectory
                    Prediction
                  </td>
                  <td class="authorcell">Ziyang Ren, Ping Wei, Haowen Tang, Huan Li, Jin Yang</td>
                </tr>
                <tr>
                  <td>257</td>
                  <td>
                    Motion Tracking with Rotated Bounding Boxes on Overhead Fisheye
                    Imagery
                  </td>
                  <td class="authorcell">Jordan Lam</td>
                </tr>
                <tr>
                  <td>308</td>
                  <td>Effective Message Hiding with Order-Preserving Mechanisms</td>
                  <td class="authorcell">Gao Yu, Xuchong QIU, Zihan Ye</td>
                </tr>
                <tr>
                  <td>329</td>
                  <td>
                    Uni-Mlip: Unified Self-Supervision for Medical Vision Language
                    Pre-training
                  </td>
                  <td class="authorcell">Ameera Bawazir, Kebin Wu, Wenbin LI</td>
                </tr>
                <tr>
                  <td>362</td>
                  <td>
                    Into the Fog: Evaluating Robustness of Multiple Object Tracking
                  </td>
                  <td class="authorcell">Nadezda Kirillova, Muhammad Jehanzeb Mirza, Horst Bischof, Horst Possegger</td>
                </tr>
                <tr>
                  <td>369</td>
                  <td>
                    Benchmarking and Optimizing Federated Learning with
                    Hardware-related Metrics
                  </td>
                  <td class="authorcell">Kai Pan, Yapeng Tian, Yinhe Han, Yiming Gan</td>
                </tr>
                <tr>
                  <td>432</td>
                  <td>
                    Channel-Partitioned Windowed Attention And Frequency Learning
                    for Single Image Super-Resolution
                  </td>
                  <td class="authorcell">Dinh Phu Tran, Dao Duy Hung, Daeyoung Kim</td>
                </tr>
                <tr>
                  <td>482</td>
                  <td>Unsupervised Hashing Network with Hyper Quantization Tree</td>
                  <td class="authorcell">Sungeun Kim, Jongbin Ryu</td>
                </tr>
                <tr>
                  <td>534</td>
                  <td>
                    Enhancing Cardiovascular Disease Prediction through Multi-Modal
                    Self-Supervised Learning
                  </td>
                  <td class="authorcell">Francesco Girlanda, Olga V. Demler, bjoern menze, Neda Davoudi</td>
                </tr>
                <tr>
                  <td>546</td>
                  <td>
                    Balancing Calibration and Performance: Stochastic Depth in
                    Segmentation BNNs
                  </td>
                  <td class="authorcell">Linghong Yao, Denis Hadjivelichkov, Andromachi Maria Delfaki, Yuanchang Liu, Brooks Paige, Dimitrios Kanoulas</td>
                </tr>
                <tr>
                  <td>563</td>
                  <td>
                    As Firm As Their Foundations: Creating Transferable Adversarial
                    Examples Across Downstream Tasks with CLIP
                  </td>
                  <td class="authorcell">Anjun Hu, Jindong Gu, Francesco Pinto, Konstantinos Kamnitsas, Philip Torr</td>
                </tr>
                <tr>
                  <td>566</td>
                  <td>
                    SuperLoRA: Parameter-Efficient Unified Adaptation of Large
                    Foundation Models
                  </td>
                  <td class="authorcell">Xiangyu Chen, Jing Liu, Ye Wang, Pu Perry Wang, Matthew Brand, Guanghui Wang, Toshiaki Koike-Akino</td>
                </tr>
                <tr>
                  <td>579</td>
                  <td>Neural Collapse Inspired Contrastive Continual Learning</td>
                  <td class="authorcell">Antoine Montmaur, Nicolas Larue, Ngoc-Son Vu</td>
                </tr>
                <tr>
                  <td>611</td>
                  <td>
                    STPose: 6D object pose estimation network based on sparse
                    attention and cross-layer connection
                  </td>
                  <td class="authorcell">Shihao Chen, Xiaobing Li, Keduo Yan, Yong Li, Dongxu Gao</td>
                </tr>
                <tr>
                  <td>619</td>
                  <td>
                    Prompt-guided Multi-modal contrastive learning for
                    Cross-compression-rate Deepfake Detection
                  </td>
                  <td class="authorcell">Ching-Yi Lai, Chiou-ting Hsu, Chih-Chung Hsu, Chia-Wen Lin</td>
                </tr>
                <tr>
                  <td>627</td>
                  <td>
                    GLPI: A Global Layered Prompt Integration approach for Explicit
                    Visual Prompt
                  </td>
                  <td class="authorcell">Yufei Gao, Bin Fu, Lei Shi, Chengming Liu, yucheng shi</td>
                </tr>
                <tr>
                  <td>659</td>
                  <td>
                    GN-FR: Generalizable Neural Radinace Fields for Flare Removal
                  </td>
                  <td class="authorcell">Gopi Raju Matta, Rahul Siddartha, RONGALI SIMHACHALA VENKATA GIRISH, Sumit Sharma, Kaushik Mitra</td>
                </tr>
                <tr>
                  <td>678</td>
                  <td>Content and Style Aware Audio-Driven Facial Animation</td>
                  <td class="authorcell">QINGJU LIU, Hyeongwoo Kim, Gaurav Bharaj</td>
                </tr>
                <tr>
                  <td>680</td>
                  <td>
                    May the Forgetting Be with You: Alternate Replay for Learning
                    with Noisy Labels
                  </td>
                  <td class="authorcell">Monica Millunzi, Lorenzo Bonicelli, Angelo Porrello, Jacopo Credi, Petter N. Kolm, Simone Calderara</td>
                </tr>
                <tr>
                  <td>681</td>
                  <td>
                    On Evaluating Adversarial Robustness of Volumetric Medical
                    Segmentation Models
                  </td>
                  <td class="authorcell">Hashmat Shadab Malik, Numan Saeed, Asif Hanif, Muzammal Naseer, Mohammad Yaqub, Salman Khan, Fahad Khan</td>
                </tr>
                <tr>
                  <td>689</td>
                  <td>
                    AggSS: An Aggregated Self-Supervised Approach for Class
                    Incremental Learning
                  </td>
                  <td class="authorcell">Jayateja Kalla, Soma Biswas</td>
                </tr>
                <tr>
                  <td>695</td>
                  <td>
                    Detecting Audio-Visual Deepfakes with Fine-Grained
                    Inconsistencies
                  </td>
                  <td class="authorcell">Marcella Astrid, Enjie Ghorbel, Djamila Aouada</td>
                </tr>
                <tr>
                  <td>721</td>
                  <td>
                    Sign Stitching: A Novel Approach to Sign Language Production
                  </td>
                  <td class="authorcell">Harry Walsh, Ben Saunders, Richard Bowden</td>
                </tr>
                <tr>
                  <td>731</td>
                  <td>
                    AutoDOM: Automated Dimension Overlay for Enhanced
                    Measurement-Guidance
                  </td>
                  <td class="authorcell">Pushpendu Ghosh, Aniket Joshi, Soumyajit Chowdhury, Promod Yenigalla</td>
                </tr>
                <tr>
                  <td>753</td>
                  <td>
                    Box for Mask and Mask for Box: weak losses for multi-task
                    partially supervised learning
                  </td>
                  <td class="authorcell">Hoàng-Ân Lê, Paul Berg, Minh Tan Pham</td>
                </tr>
                <tr>
                  <td>882</td>
                  <td>
                    A Multimodal Network on Handwritten Chinese Character Error
                    Correction
                  </td>
                  <td class="authorcell">Haizhao Sun, Yu Ning, Xu Ji, Chuang Zhang, Ming Wu</td>
                </tr>
                <tr>
                  <td>885</td>
                  <td>
                    Efficient Data Source Relevance Quantification for Multi-Source
                    Neural Networks
                  </td>
                  <td class="authorcell">Jakob Gawlikowski, Nina Maria Gottschling</td>
                </tr>
                <tr>
                  <td>887</td>
                  <td>
                    Blocks as Probes: Dissecting Categorization Ability of Large
                    Multimodal Models
                  </td>
                  <td class="authorcell">Bin Fu, Qiyang Wan, Jialin Li, Ruiping Wang, Xilin Chen</td>
                </tr>
                <tr>
                  <td>103</td>
                  <td>
                    Prompting Diffusion Representations for Cross-Domain Semantic
                    Segmentation
                  </td>
                  <td class="authorcell">Rui Gong, Martin Danelljan, Han Sun, Julio Delgado Mangas, Nikolay Marin, Luc Van Gool</td>
                </tr>
                <tr>
                  <td>200</td>
                  <td>
                    Towards Generative Class Prompt Learning for Fine-grained Visual
                    Recognition
                  </td>
                  <td class="authorcell">Soumitri Chattopadhyay, Sanket Biswas, Emanuele Vivoli, Josep Llados</td>
                </tr>
                <tr>
                  <td>406</td>
                  <td>
                    When Text and Images Don&#39;t Mix: Bias-Correcting
                    Language-Image Similarity Scores for Anomaly Detection
                  </td>
                  <td class="authorcell">Adam Goodge, Bryan Hooi, Wee Siong Ng</td>
                </tr>
                <tr>
                  <td>615</td>
                  <td>
                    Measuring Physical Plausibility of 3D Human Poses Using Physics
                    Simulation
                  </td>
                  <td class="authorcell">Nathan Louis, Mahzad Khoshlessan, Jason J Corso</td>
                </tr>
                <tr>
                  <td>754</td>
                  <td>
                    Revisiting Image Captioning Training Paradigm via Direct
                    CLIP-based Optimization
                  </td>
                  <td class="authorcell">Nicholas Moratelli, Davide Caffagni, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara</td>
                </tr>
              </table>
            </div>
          </details>
          <div class="loc">
            Room: Hall 2
          </div>

        </td>
      </tr>
      <tr>
        <th rowspan="44">15:15 - 17:00</th>
        <td class="tdoral" colspan="2">
          <details>
            <summary>Papers Presented</summary>
            <div>
              <table class="responsive-table">

                <tr>
                  <td>14</td>
                  <td>Efficiency-preserving Scene-adaptive Object Detection</td>
                  <td class="authorcell">Zekun Zhang, Vu Quang Truong, Minh Hoai</td>
                </tr>
                <tr>
                  <td>114</td>
                  <td>
                    Key-point Guided Deformable Image Manipulation Using Diffusion
                    Model
                  </td>
                  <td class="authorcell">Seok-Hwan Oh, Guil Jung, Myeong-Gee Kim, Sang-yun Kim, Young-Min Kim, hyeonjik lee, Hyuksool Kwon, Hyeonmin Bae</td>
                </tr>
                <tr>
                  <td>416</td>
                  <td>
                    Taming the Tail: Leveraging Asymmetric Loss and Padé
                    Approximation to Overcome Long-Tailed Class Imbalance
                  </td>
                  <td class="authorcell">Pankhi Kashyap, Pavni Tandon, Sunny Gupta, Abhishek Tiwari, Ritwik Kulkarni, Kshitij Sharad Jadhav</td>
                </tr>
                <tr>
                  <td>517</td>
                  <td>Interpretable Long-term Action Quality Assessment</td>
                  <td class="authorcell">Xu Dong, Xinran Liu, Wanqing Li, Anthony Adeyemi-Ejeye, Andrew Gilbert</td>
                </tr>
                <tr>
                  <td>545</td>
                  <td>
                    Vision-Language Guidance for LiDAR-based Unsupervised 3D Object
                    Detection
                  </td>
                  <td class="authorcell">Christian Fruhwirth-Reisinger, Wei Lin, Dušan Malić, Horst Bischof, Horst Possegger</td>
                </tr>
                <tr>
                  <td>23</td>
                  <td>
                    Alignment-aware Patch-level Routing for Dynamic Video Frame
                    Interpolation
                  </td>
                  <td class="authorcell">Ban Chen, Xin Jin, LONG HAI WU, Jie Chen, Ilhyun Cho, Cheul-hee Hahm</td>
                </tr>
                <tr>
                  <td>34</td>
                  <td>TalkLoRA: Low-Rank Adaptation for Speech-Driven Animation</td>
                  <td class="authorcell">Jack Saunders, Vinay P. Namboodiri</td>
                </tr>
                <tr>
                  <td>47</td>
                  <td>
                    Group Activity Recognition via Spatio-Temporal Reasoning of Key
                    Instances
                  </td>
                  <td class="authorcell">Haoting He, Yaochen Li, Yutong Wang, Gaojie Li, Wei Guo, Runlin Zou</td>
                </tr>
                <tr>
                  <td>74</td>
                  <td>
                    ControlDreamer: Stylized 3D Generation with Multi-View
                    ControlNet
                  </td>
                  <td class="authorcell">Yeongtak Oh, Jooyoung Choi, Yongsung Kim, Minjun Park, Chaehun Shin, Sungroh Yoon</td>
                </tr>
                <tr>
                  <td>102</td>
                  <td>
                    Distribution-Aware Calibration for Object Detection with Noisy
                    Bounding Boxes
                  </td>
                  <td class="authorcell">Donghao Zhou, Jialin Li, Jinpeng Li, Jiancheng Huang, Qiang Nie, Yong Liu, Bin-Bin Gao, Qiong Wang, Pheng-Ann Heng, Guangyong Chen</td>
                </tr>
                <tr>
                  <td>108</td>
                  <td>
                    MoManifold: Learning to Measure 3D Human Motion via Decoupled
                    Joint Acceleration Manifolds
                  </td>
                  <td class="authorcell">Ziqiang Dang, Tianxing Fan, Boming Zhao, Xujie Shen, 王 磊, Guofeng Zhang, Zhaopeng Cui</td>
                </tr>
                <tr>
                  <td>140</td>
                  <td>
                    Scalable Frame Sampling for Video Classification: A Semi-Optimal
                    Policy Approach with Reduced Search Space
                  </td>
                  <td class="authorcell">Junho Lee, Jeongwoo Shin, Seung Woo Ko, Seongsu Ha, Joonseok Lee</td>
                </tr>
                <tr>
                  <td>147</td>
                  <td>
                    MCDS-VSS: Moving Camera Dynamic Scene Video Semantic
                    Segmentation by Filtering with Self-Supervised Geometry and
                    Motion
                  </td>
                  <td class="authorcell">Angel Villar-Corrales, Moritz Austermann, Sven Behnke</td>
                </tr>
                <tr>
                  <td>180</td>
                  <td>
                    JEAN: Joint Expression and Audio-guided NeRF-based Talking Face
                    Generation
                  </td>
                  <td class="authorcell">Sai Tanmay Reddy Chakkera, Aggelina Chatziagapi, Dimitris Samaras</td>
                </tr>
                <tr>
                  <td>184</td>
                  <td>
                    Reclaiming Residual Knowledge: A Novel Paradigm to Low-Bit
                    Quantization
                  </td>
                  <td class="authorcell">Roisin Luo, Alexandru Drimbarean, James McDermott, Colm O'Riordan</td>
                </tr>
                <tr>
                  <td>211</td>
                  <td>
                    Align-DETR: Enhancing End-to-end Object Detection with Aligned
                    Loss
                  </td>
                  <td class="authorcell">Zhi Cai, Songtao Liu, Guodong Wang, Zeming Li, Zheng Ge, Xiangyu Zhang, Di Huang</td>
                </tr>
                <tr>
                  <td>245</td>
                  <td>
                    Enhancing 3D Hand Pose Estimation via Dense Ordinal Regression
                    Network
                  </td>
                  <td class="authorcell">Yamin Mao, Zhihua Liu, Weiming Li, SoonYong Cho, Qiang Wang, Xiaoshuai Hao</td>
                </tr>
                <tr>
                  <td>288</td>
                  <td>
                    PawFACS: Leveraging Semi-Supervised Learning for Pet Facial
                    Action Recognition
                  </td>
                  <td class="authorcell">Anandavardhan Hegde, Sudha Velusamy, Narayan Kothari, Aman Bahuguna, Apnesh Rawat, Hema Sathiamurthy, Ankit Raja</td>
                </tr>
                <tr>
                  <td>307</td>
                  <td>
                    Discovering an Image-Adaptive Coordinate System for Photography
                    Processing
                  </td>
                  <td class="authorcell">Ziteng Cui, Lin Gu, Tatsuya Harada</td>
                </tr>
                <tr>
                  <td>318</td>
                  <td>
                    Mumpy: Multilateral Temporal-view Pyramid Transformer for Video
                    Inpainting Detection
                  </td>
                  <td class="authorcell">Ying Zhang, Yuezun Li, Bo Peng, Jiaran Zhou, Huiyu Zhou, Junyu Dong</td>
                </tr>
                <tr>
                  <td>323</td>
                  <td>
                    Complete the Feature Space: Diffusion-Based Fictional ID
                    Generation for Face Recognition
                  </td>
                  <td class="authorcell">Myeong-Yeon Yi, DongJae Lee, Naeun Ko, Yonghyun Jeong, Sang-goo Lee, Seunggyu Chang</td>
                </tr>
                <tr>
                  <td>335</td>
                  <td>
                    SignVTCL: Multi-Modal Continuous Sign Language Recognition
                    Enhanced by Visual-Textual Contrastive Learning
                  </td>
                  <td class="authorcell">Hao Chen, Jiaze Wang, Ziyu Guo, Jinpeng Li, Donghao Zhou, Bian Wu, Chenyong Guan, Guangyong Chen, Pheng-Ann Heng</td>
                </tr>
                <tr>
                  <td>352</td>
                  <td>DiffusedWrinkles: A Diffusion-Based Model for Data-Driven Garment Animation</td>
                  <td class="authorcell">Raquel Vidaurre, Elena Garces, Dan Casas</td>
                </tr>
                <tr>
                  <td>384</td>
                  <td>Few-Shot Classification of Interactive Activities of Daily Living (InteractADL)</td>
                  <td class="authorcell">Zane Durante, Robathan Harries, Edward Vendrow, Zelun Luo, Yuta Kyuragi, Kazuki Kozuka, Li Fei-Fei, Ehsan Adeli</td>
                </tr>
                <tr>
                  <td>388</td>
                  <td>ACIL: Active Class Incremental Learning for Image Classification</td>
                  <td class="authorcell">Aditya Bhattacharya, Debanjan Goswami, Shayok Chakraborty</td>
                </tr>
                <tr>
                  <td>414</td>
                  <td>NSSR-DIL: Null-Shot Image Super-Resolution Using Deep Identity Learning</td>
                  <td class="authorcell">Sree Rama Vamsidhar S, Gorthi Rama Krishna Sai Subrahmanyam</td>
                </tr>
                <tr>
                  <td>421</td>
                  <td>Rethinking Domain Adaptive Optic Disc and Cup Segmentation in Fundus Image through Dynamic
                    Diffusion Flow</td>
                  <td class="authorcell">Canran Li, Dongnan Liu, Weidong Cai</td>
                </tr>
                <tr>
                  <td>426</td>
                  <td>Unified Compositional Query Machine with Multimodal Consistency for Video-based Human Activity
                    Recognition</td>
                  <td class="authorcell">Tuyen Tran, Thao Minh Le, Duy Hung Tran, Truyen Tran</td>
                </tr>
                <tr>
                  <td>433</td>
                  <td>
                    Separated and Independent Contrastive Learning on Labeled and
                    Unlabeled Samples: Boosting Performance on Long-tail
                    Semi-supervised Learning
                  </td>
                  <td class="authorcell">Dongyoung Kim, Jeong-Gun Lee, WonSook Lee</td>
                </tr>
                <tr>
                  <td>448</td>
                  <td>Learning to Project for Cross-Task Knowledge Distillation</td>
                  <td class="authorcell">Dylan Auty, Roy Miles, Benedikt Kolbeinsson, Krystian Mikolajczyk</td>
                </tr>
                <tr>
                  <td>493</td>
                  <td>
                    Spike-SLR: An Energy-efficient Parallel Spiking Transformer for
                    Event-based Sign Language Recognition
                  </td>
                  <td class="authorcell">Xinxu Lin, Mingxuan Liu, Kezhuo Liu, Hong Chen</td>
                </tr>
                <tr>
                  <td>499</td>
                  <td>
                    MotionMAE: Self-supervised Video Representation Learning with
                    Motion-Aware Masked Autoencoders
                  </td>
                  <td class="authorcell">Haosen Yang, Deng Huang, Bin Wen, Jiannan Wu, Hongxun Yao, Yi Jiang, Xiatian Zhu, Zehuan Yuan</td>
                </tr>
                <tr>
                  <td>505</td>
                  <td>
                    FLARE up your data: Diffusion-based Augmentation Method in
                    Astronomical Imaging
                  </td>
                  <td class="authorcell">Mohammed Talha Alam, Raza Imam, Mohsen Guizani, Fakhri Karray</td>
                </tr>
                <tr>
                  <td>524</td>
                  <td>
                    A self-supervised cyclic neural-analytic approach for novel view
                    synthesis and 3D reconstruction
                  </td>
                  <td class="authorcell">Dragos Costea, Alina Marcu, Marius Leordeanu</td>
                </tr>
                <tr>
                  <td>537</td>
                  <td>
                    Out-Of-Distribution Detection for Audio-visual Generalized
                    Zero-Shot Learning: A General Framework
                  </td>
                  <td class="authorcell">Liuyuan Wen</td>
                </tr>
                <tr>
                  <td>599</td>
                  <td>
                    VLAVAD: Vision-Language Models Assisted Unsupervised Video
                    Anomaly Detection
                  </td>
                  <td class="authorcell">Changkang Li, Yalong Jiang</td>
                </tr>
                <tr>
                  <td>657</td>
                  <td>G3FA: Geometry-guided GAN for Face Animation</td>
                  <td class="authorcell">Alireza Javanmardi, Alain Pagani, Didier Strickerr</td>
                </tr>
                <tr>
                  <td>723</td>
                  <td>
                    $ControlEdit: A MultiModal Local Clothing Image Editing Method$
                  </td>
                  <td class="authorcell">Di Cheng, Yingjie Shi, sun shixin, JiaFu Zhang, weijing wang, YULiu</td>
                </tr>
                <tr>
                  <td>727</td>
                  <td>
                    Optimising Diffusion Models for Histopathology Image Synthesis
                  </td>
                  <td class="authorcell">Victoria Porter, Richard Gault, Stephanie G Craig, Jacqueline James</td>
                </tr>
                <tr>
                  <td>746</td>
                  <td>
                    Adapting MIMO video restoration networks to low latency
                    constraints
                  </td>
                  <td class="authorcell">Valéry Dewil, Zhe Zheng, Arnaud Barral, Lara Raad, Nao Nicolas, Ioannis Cassagne, Jean-michel Morel, Gabriele Facciolo, Bruno Galerne, Pablo Arias</td>
                </tr>
                <tr>
                  <td>755</td>
                  <td>
                    PlainMamba: Improving Non-Hierarchical Mamba in Visual
                    Recognition
                  </td>
                  <td class="authorcell">Chenhongyi Yang, Zehui Chen, Miguel Espinosa, Linus Ericsson, Zhenyu Wang, Jiaming Liu, Elliot J. Crowley</td>
                </tr>
                <tr>
                  <td>790</td>
                  <td>
                    FILS: Self-Supervised Video Feature Prediction In Semantic
                    Language Space
                  </td>
                  <td class="authorcell">Mona Ahmadian, Frank Guerin, Andrew Gilbertn</td>
                </tr>
                <tr>
                  <td>900</td>
                  <td>
                    Direct-Sum Approach to Integrate Losses Via Classifier Subspace
                  </td>
                  <td class="authorcell">Takumi Kobayashi</td>
                </tr>
                <tr>
                  <td>911</td>
                  <td>A simple Color Correction Matrix for RAW Reconstruction</td>
                  <td class="authorcell">Anqi Liu, Shiyi Mu, Shugong Xu</td>
                </tr>
              </table>
          </details>
          <div class="loc">
            Room: Hall 2
          </div>

        </td>
      </tr>

    </table>
  </details>
</div>

<div class="tableevent">
  <details open name="events">
    <summary class="sidebyside workshop">
      <div class="">
        Doctoral Consortium
      </div>
      <div class=" rightaligned">
        10:00 - 13:00
      </div>
    </summary>
    <table>
      <tr>
        <th rowspan="13">Chair: Richard Menzies and George Killick</th>
        <th>10:00 - 10:15</th>
        <td class="tdoral">Fatemeh Amerehi</td>
        <td class="tdoral">
          Toward Comprehensive Neural Network Robustness
        </td>
      </tr>
      <tr>
        <th>10:15 - 10:30</th>
        <td class="tdoral">Zahra Babaiee</td>
        <td class="tdoral">
          Unveiling the Unseen: Identifiable Clusters in Trained Depthwise Convolutional Kernels
        </td>
      </tr>
      <tr>
        <th>10:30 - 10:45</th>
        <td class="tdoral">Jack Saunders</td>
        <td class="tdoral">
          Style and Speech in Facial Animation
        </td>
      </tr>
      <tr>
        <th>10:45 - 11:00</th>
        <td class="tdoral">Muhammad Akhtar Munir</td>
        <td class="tdoral">
          Exploring Advanced Calibration Loss Techniques for Vision-Language Models
        </td>
      </tr>
      <tr>
        <th>11:00 - 11:15</th>
        <td class="tdoral">
          Break
        </td>
        <td class="tdoral">Break</td>
      </tr>
      <tr>
        <th>11:15 - 11:30</th>
        <td class="tdoral">Filippos Gouidis</td>
        <td class="tdoral">
          Recognizing object states by combining data-driven and symbolic methods
        </td>
      </tr>
      <tr>
        <th>11:30 - 11:45</th>
        <td class="tdoral">Remco Royen</td>
        <td class="tdoral">
          Addressing labelling, complexity, latency, and scalability in deep learning-based processing of point clouds
        </td>
      </tr>
      <tr>
        <th>11:45 - 12:15</th>
        <td class="tdoral">Speaker: Md. Mostafa Kamal Sarker (Technovative Solutions LTD)</td>
        <td class="tdoral">
          Dr Sarker is the Lead AI Research Scientist at Technovative Solutions LTD (TVS) and a Visiting Fellow at the
          University of Oxford. He's an expert in artificial intelligence, computer vision, and deep learning. His
          research has significantly impacted clinical AI, biomedical image analysis, and digital healthcare, evident in
          his 40+ peer-reviewed publications. At BMVC2024, he'll share his valuable insights and guide aspiring
          researchers on transitioning from academia to industry and discuss the exciting opportunities this path
          offers.
        </td>
      </tr>
      <tr>
        <th>12:15 - 13:00</th>
        <td class="tdoral">Mentor Session</td>
        <td class="tdoral"></td>
        </td>
      </tr>
      <tr>
        <td colspan="3">
          <div class="loc">
            Room: M2
          </div>
        </td>
      </tr>
    </table>
  </details>
</div>

<div class="tableevent">
  <details open name="events">
    <summary class="sidebyside workshop">
      <div class="">
        Workshop Sessions
      </div>
      <div class=" rightaligned">
        09:00 - 18:00
      </div>
    </summary>
    <table>
      <tr>
        <th class="wide">09:00 - 18:00</th>
        <td>Robust Recognition in the Open World
          </p>
          <a href="https://rrow2024.github.io">https://rrow2024.github.io</a>
          <div class="loc">
            Room: M3
          </div>
        </td>
      </tr>
      <tr>
        <th class="wide">14:00 - 18:00</th>
        <td>DIFA: Deep Learning-based Image Fusion and Its Applications
          </p>
          <a href="https://difa2024.github.io">https://difa2024.github.io</a>
          <div class="loc">
            Room: M2
          </div>
        </td>

      </tr>
    </table>
  </details>
</div>

<div class="tableevent">
  <details name="events">
    <summary class="sidebyside oral">
      <div class="">
        Oral Session - Machine Vision in Challenging Scenarios
      </div>
      <div class=" rightaligned">
        11:45 - 13:00
      </div>
    </summary>
    <table>

      <tr>
        <th rowspan="6">Chair: Amey Pore</th>
        <th>11:45</th>
        <td class="tdoral">103</td>
        <td class='tdoral'>
          <div class='oralcell'>
            <div>
              Prompting Diffusion Representations for Cross-Domain Semantic Segmentation
            </div>
            <div>
              Rui Gong, Martin Danelljan, Han Sun, Julio Delgado Mangas, Nikolay Marin, Luc Van Gool
            </div>
          </div>
        </td>
        </td>
      </tr>
      <tr>
        <th>12:00</th>
        <td class="tdoral">200</td>
        <td class='tdoral'>
          <div class='oralcell'>
            <div>
              Towards Generative Class Prompt Learning for Fine-grained Visual Recognition
            </div>
            <div>
              Soumitri Chattopadhyay, Sanket Biswas, Emanuele Vivoli, Josep Llados
            </div>
          </div>
        </td>
        </td>
      </tr>
      <tr>
        <th>12:15</th>
        <td class="tdoral">406</td>
        <td class='tdoral'>
          <div class='oralcell'>
            <div>
              When Text and Images Don&#39;t Mix: Bias-Correcting Language-Image Similarity Scores for Anomaly Detection
            </div>
            <div>
              Adam Goodge, Bryan Hooi, Wee Siong Ng
            </div>
          </div>
        </td>
        </td>
      </tr>
      <tr>
        <th>12:30</th>
        <td class="tdoral">615</td>
        <td class='tdoral'>
          <div class='oralcell'>
            <div>
              Measuring Physical Plausibility of 3D Human Poses Using Physics Simulation
            </div>
            <div>
              Nathan Louis, Mahzad Khoshlessan, Jason J Corso
            </div>
          </div>
        </td>
        </td>
      </tr>
      <tr>
        <th>12:45</th>
        <td class="tdoral">754</td>
        <td class='tdoral'>
          <div class='oralcell'>
            <div>
              Revisiting Image Captioning Training Paradigm via Direct CLIP-based Optimization
            </div>
            <div>
              Nicholas Moratelli, Davide Caffagni, Marcella Cornia, Lorenzo Baraldi, Rita Cucchiara
            </div>
          </div>
        </td>
        </td>
      </tr>
      <tr>
        <td colspan="3">
          <div class="loc">
            Room: M1
          </div>
        </td>
      </tr>
    </table>
  </details>
</div>

<div class="tableevent">
  <details name="events">
    <summary class="sidebyside oral">
      <div class="">
        Oral Session - Image Quality Algorithms
      </div>
      <div class=" rightaligned">
        14:00 - 15:15
      </div>
    </summary>
    <table>
      
      <tr>
        <th rowspan="6">Chair: Jefersson A. dos Santos</th>
        <th>14:00</th>
        <td class="tdoral">14</td>
         <td class='tdoral'>
          <div class='oralcell'>
           <div>
            Efficiency-preserving Scene-adaptive Object Detection
           </div>
           <div>
            Zekun Zhang, Vu Quang Truong, Minh Hoai
           </div>
          </div>
         </td>
      </tr>
      <tr>
        <th>14:15</th>
        <td class="tdoral">114</td>
         <td class='tdoral'>
          <div class='oralcell'>
           <div>
            Key-point Guided Deformable Image Manipulation Using Diffusion Model
           </div>
           <div>
            Seok-Hwan Oh, Guil Jung, Myeong-Gee Kim, Sang-yun Kim, Young-Min Kim, hyeonjik lee, Hyuksool Kwon, Hyeonmin Bae
           </div>
          </div>
         </td>
        </td>
      </tr>
      <tr>
        <th>14:30</th>
        <td class="tdoral">416</td>
         <td class='tdoral'>
          <div class='oralcell'>
           <div>
            Taming the Tail: Leveraging Asymmetric Loss and Padé Approximation to Overcome Long-Tailed Class Imbalance
           </div>
           <div>
            Pankhi Kashyap, Pavni Tandon, Sunny Gupta, Abhishek Tiwari, Ritwik Kulkarni, Kshitij Sharad Jadhav
           </div>
          </div>
         </td>
        </td>
      </tr>
      <tr>
        <th>14:45</th>
        <td class="tdoral">517</td>
         <td class='tdoral'>
          <div class='oralcell'>
           <div>
            Interpretable Long-term Action Quality Assessment
           </div>
           <div>
            Xu Dong, Xinran Liu, Wanqing Li, Anthony Adeyemi-Ejeye, Andrew Gilbert
           </div>
          </div>
         </td>
      </tr>
      <tr>
        <th>15:00</th>
        <td class="tdoral">545</td>
         <td class='tdoral'>
          <div class='oralcell'>
           <div>
            Vision-Language Guidance for LiDAR-based Unsupervised 3D Object Detection
           </div>
           <div>
            Christian Fruhwirth-Reisinger, Wei Lin, Dušan Malić, Horst Bischof, Horst Possegger
           </div>
          </div>
         </td>
        </td>
      </tr>
      <tr>
        <td colspan="3">
          <div class="loc">
            Room: M1
          </div>
        </td>
      </tr>

    </table>
  </details>
</div>

</br>
<div class="image-block text-center">
  <img src="{{ site.baseurl }}/imgs_2024/sponsors.png" alt="sponsors-logos" class="img-fluid" style="max-height: 300px;">
</div>