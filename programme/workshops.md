---
layout: default_sparse
title: Workshops
permalink: /programme/workshops/
index: 15
---

<h5>Thursday, 23rd November 2023</h5>

<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">Computer Vision for Games and Games for Computer Vision (CVG)</h4>
            <p class=" mb-1"><small>Thursday, 23rd November 2023</small></p>
            <p class=" mb-1"><small>Website: <a href="https://cvg2023.institutedigitalgames.com/" target="_blank">https://cvg2023.institutedigitalgames.com/</a></small></p>
            <p class=" mb-1"><small>Organisers: Chintan Trivedi (University of Malta), Matthew Guzdial (University of Alberta), Konstantinos Makantasis (University of Malta), Tim Pearce (Microsoft Research), Roberta Raileanu (Meta AI), Marguerite deCourcelle (Blockade Games), Nicu Sebe (University of Trento), Julian Togelius (New York University; modl.ai), Georgios N. Yannakakis (University of Malta; modl.ai)</small></p>
            <p class=" mb-1"><small>Contact: cvgworkshop@gmail.com</small></p>
            <p class=" mb-1"><small>Venue: P&J (Main Conference Centre)</small></p>
            <br>
            <p class="pb-2">This workshop contains two main tracks. The first track focuses on introducing novel techniques within computer vision research that can advance the field of digital games. The second track, instead, focuses on leveraging game technologies to advance state-of-the-art techniques in computer vision. The list of topics below is not inclusive of all research directions that will be represented in this workshop.
 <br>
  <br>
1) Computer Vision for Games 
<ul>
    <li>CV for game-playing, game testing and player modeling.</li>
    <li>Data-driven CV to improve game graphics, animations, level-design, etc.</li>
    <li>HCI through visual interfaces (gestures, posture, gaze, etc.).</li>
    <li>Extended reality games.</li>
    <li>Synthetic data and media generation based on users' emotions, behavior, etc.</li>
    <li>Improving real-time applicability of vision models integrated within games and game engines.</li>
    <li>Computer vision for procedural content generation.</li>
   </ul> 
2) Games for Computer Vision 
<br>
<br>
<ul>
    <li>Rich game-based labeled datasets for tasks such as object detection, segmentation, or depth and flow estimation.</li>
    <li>Generalization and robustness in vision models leveraging a plethora of existing commercial games.</li>
    <li>Game worlds that aid data augmentation techniques.</li>
    <li>Unsupervised pre-training of image/video representations and world transition models from gameplay data.</li>
    <li>Forward modeling in and for games.</li>
    <li>Ethics of game-based data collection and inference.</li>
</ul> <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
</p>
        </div>
    </div>
</div></div>



<br>
<br>

<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">The Third Workshop on Computational Aspects of Deep Learning (CADL 2023)</h4>
            <p class=" mb-1"><small>Thursday, 23rd November 2023</small></p>
            <p class=" mb-1"><small>Website: <a href="https://ailb-web.ing.unimore.it/cadl2023/" target="_blank">https://ailb-web.ing.unimore.it/cadl2023/</a></small></p>
            <p class=" mb-1"><small>Organisers: Giuseppe Fiameni (NVIDIA), Iuri Frosio (NVIDIA), Claudio Baecchi (Small Pixels; University of Florence), Frederic Pariente (NVIDIA), Lorenzo Baraldi (University of Modena and Reggio Emilia)</small></p>
            <p class=" mb-1"><small>Contact: ifrosio@nvidia.com</small></p>
            <p class=" mb-1"><small>Venue: P&J (Main Conference Centre)</small></p>
            <br>
            <p class="pb-2">Over the past decade, deep learning has revolutionized computer science by enabling remarkable advances in prediction models across various research fields and applications, such as computer vision, natural language processing, pattern recognition, and generative models. This transformative shift has made AI a computational science where massive models with millions of parameters are trained on large-scale computing infrastructures, accelerating scientific discovery and leading to more accurate results. However, harnessing such computational power requires careful optimization and design of neural architectures as well as their training procedures that play an increasingly crucial role in shaping research pace, model effectiveness, applicability at scale, and energy consumption reduction.
            <br>
The advent of transformer models and large language models, such as BERT or GPT, has further transformed the field of natural language processing, enabling unprecedented levels of language understanding and generation. These models have significantly advanced applications like chatbots, virtual assistants, and machine translation. The development, training and inference costs of such models (both in terms of money and environment) is non negligible. Furthermore, the development of transformer-based models has introduced a new paradigm for deep learning, leading to a range of state-of-the-art models in various domains.
<br>
<br>
The workshop on "Computational Aspects of Deep Learning" aims to bring together experts in deep learning to exchange ideas, discuss current challenges, and identify solutions that can advance the field in a computationally efficient and energy-saving way. The workshop will focus on the development of deep neural network architectures in high-density data fields, such as video processing, action recognition, and high-resolution image understanding. It will also cover research fields that involve sequential predictions, like reinforcement learning, embodied AI, and natural language understanding and generation.
The workshop will encourage submissions that address computationally intensive scenarios from multiple perspectives, such as architectural design, data preparation and processing, operator design, training strategies, and distributed and large-scale training. It will provide the attendees with theoretical and practical instruments for the deployment of computationally effective AI solutions. Therefore, submissions will also be evaluated based on their ability to reduce energy consumption by designing novel and effective model architectures and training procedures. The workshop will also promote positive criticism of current data-intensive trends in machine learning, and encourage new perspectives and solutions. In summary, the advent of transformer models and large language models has further propelled the field of deep learning, and this workshop aims to facilitate the continued advancement of the field in a computationally efficient and energy-saving way.
<br>
<br>
The following topics are of interest for the workshop, but not limited to:
<br>
 <ul>
<li>Developing optimization strategies for reducing the energy consumption in deep learning</li>
<li>Design of novel architectures and operators that are suitable for data-intensive scenarios</li>
<li>Developing distributed, efficient reinforcement learning algorithms</li>
<li>Implementing large-scale pre-training techniques for real-world applications</li>
<li>Developing distributed training approaches and architectures</li>
<li>Utilizing HPC and massively parallel architectures for deep learning</li>
<li>Exploring frameworks and optimization algorithms for training deep networks</li>
<li>Utilizing model pruning, gradient compression techniques, and quantization to reduce the computational complexity</li>
<li>Developing methods to reduce the memory/data transmission footprint</li>
<li>Developing methods and differentiable metrics to estimate computational costs, energy consumption and power consumption of models</li>
<li>Designing, implementing and using hardware accelerators for deep learning</li>
<li>Developing efficient and cost saving models and methods that promote diversity and inclusivity in the field of deep learning.</li>
<li>Speed up of the training and inference of GPT and other generative models</li>
            </ul>
<br>
The workshop is organized in close collaboration with the NVIDIA AI Technology Center. Diversity and inclusion are critical to NVIDIA’s mission and key priorities for directors and management as well as with every employee. To address this point, we will ask proposers to add a paragraph into respective proposals to explain how their research can improve AI adoption and scientific discovery in countries where computational resources are scarce or limited, reduce energy consumption, favor inclusion, and leverage portable devices in remote areas where energy is poorly available.</p> <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
    </div>
</div></div>


<br>
<br>

<h5>Friday, 24th November 2023</h5>

<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">Project Aria for All-Day Egocentric Research</h4>
            <p class=" mb-1"><small>Friday, 24th November 2023</small></p>
            <p class=" mb-1"><small>Website: <a href="https://www.projectaria.com/events/bmvc2023/" target="_blank">https://www.projectaria.com/events/bmvc2023/</a></small></p>
            <p class=" mb-1"><small>Organisers: Edward Miller (Meta), Richard Newcombe (Meta), Vasileios Balntas (Meta), Xiaqing Pan (Meta), Zhaoyang Lv (Meta), Pierre Moulon (Meta)</small></p>
            <p class=" mb-1"><small>Contact: edwardmiller@meta.com</small></p>
            <p class=" mb-1"><small>Venue: Robert Gordon University, Sir Ian Wood Building, Garthdee Campus</small></p>
            <br>
            <p class="pb-2">In this workshop, we will cover a broad range of research topics related to the challenges of all-day wearable egocentric devices (such as AR glasses), including visual and non-visual localization and mapping, static and dynamic object detection and spatialization, human pose estimation, and building geometry estimation. Exploration of these research areas will be facilitated by the use of Project Aria, a research device in an all-day wearable glasses form-factor. Specifically, we will share research approaches to three research challenges related to object detection and building geometry estimation, launched at CVPR earlier in June. At BMVC 2023, we will announce winners of the announced challenges and invite challenge participants to present their methods with the research community. In addition, we will also announce new challenges related to object detection at this year’s BMVC workshop.</p><iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
    </div>
</div></div>
<br>
<br>


<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">The 1st Workshop in Video Understanding and its Applications (VUA)</h4>
            <p class=" mb-1"><small>Friday, 24th November 2023</small></p>
            <p class=" mb-1"><small>Website: <a href="https://vua-bmvc.github.io/" target="_blank">https://vua-bmvc.github.io/</a></small></p>
            <p class=" mb-1"><small>Organisers: Faegheh Sardari (University of Surrey), Armin Mustafa (University of Surrey), Asmar Nadeem (University of Surrey), Robert Dawes (BBC), Adrian Hilton (University of Surrey)</small></p>
            <p class=" mb-1"><small>Contact: f.sardari@surrey.ac.uk</small></p>
            <p class=" mb-1"><small>Venue: Robert Gordon University, Sir Ian Wood Building, Garthdee Campus</small></p>
            <br>
            <p class="pb-2">Video understanding is a popular field in computer vision and AI where we aim to learn/assess the world around us from video footage and can benefit many real-world applications, such as training and education, patient monitoring, sports assessment, and security systems. By automating these applications through video analysing, not only we can save money and time for their users, but also, we can decrease human errors. Despite the recent advances in the other areas of computer vision, e.g. image analysis, video understanding is still an unsolved problem and is considered a very challenging task.

The proposed workshop on video understanding aims to address the challenges in this field by making the following contributions:

<ul>
<li>Bringing together leading experts in the field of video understanding to help propel the field forward. This includes junior and senior researchers, with equal representation and contribution from academia and industry</li>
<li>The workshop also aims to stimulate and accelerate research progress in the field of video understanding to match the requirements of real-world applications by identifying the challenges and ways to address them through a panel discussion between experts, presenters and attendees</li>
</ul>
The topics covered by the workshop include, but are not limited to:

<ul>
<li>Application of Video Understanding to healthcare and media production</li>
<li>View-invariant and 3D video understanding (e.g. 3D action recognition)</li>
<li>Transformer for video understanding</li>
<li>Generating synthetic data for video understating tasks</li>
<li>Self-supervised learning for video understanding</li>
<li>Multi-modal video understanding</li>
<li>Action/event detection</li>
<li>Video captioning</li>
<li>Video editing and summarization</li>
<li>Videography/virtual cinematography</li>
<li>Video search and retrieval</li>
</ul> <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
</p>

        </div>
    </div>
</div></div>
<br>
<br>

<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">Workshop on Machine Vision for Earth Observation and Environment Monitoring (MVEO)</h4>
            <p class=" mb-1"><small>Friday, 24th November 2023</small></p>
            <p class=" mb-1"><small>Website: <a href="https://mveo.github.io" target="_blank">https://mveo.github.io</a></small></p>
            <p class=" mb-1"><small>Organisers: Chunbo Luo (University of Exeter), Diego Marcos (Inria Université ́Côte d’Azur), Fabiana Di Ciaccio (University of Florence), Huiyu Zhou (University of Leicester), Jan Boehm (University College London), Jefersson A. dos Santos, (University of Stirling), Keiller Nogueira (University of Stirling), Paolo Russo (Sapienza University of Rome), Ribana Roscher (Research Center Jülich; University of Bonn), Ronny Hänsch (German Aerospace Center)</small></p>
            <p class=" mb-1"><small>Contact: paolo.russo@uniroma1.it, keiller.nogueira@stir.ac.uk</small></p>
            <p class=" mb-1"><small>Venue: National Subsea Centre, 3 International Ave, Dyce</small></p>
            <br>
            <p class="pb-2">The primary goal of this workshop is to foster collaboration and idea exchange among the Computer Vision, Remote Sensing and Environmental Monitoring communities, both nationally and internationally. We aim to bring together researchers and experts from the three fields to promote interdisciplinary research, encourage innovative computer vision approaches for automated interpretation of Earth observation and other correlated data, and enhance knowledge within the vision community for this rapidly evolving and highly impactful area of research. The implications of this research are far-reaching, affecting human society, economy, industry, and the environment.
<br>
<br>
Precisely, a non-exhaustive list of topics of interest includes the following:
<li>Methods: Data-centric machine learning; remote sensing data + language processing (such as Large Language Models) models; open-set, open-world, and open long-tailed recognition; multi-resolution, multi-temporal, multi-sensor, multi-modal approaches; generative models (GANs, stable diffusion, etc); self-, weakly, semi-, and unsupervised approaches; human-in-the-loop and active learning; etc.</li>
<li>Tasks: Classification; object detection; segmentation (universal, semantic, panoptic, and/or instance); data augmentation and improvement; deep fake; domain adaptation and concept drift; super-resolution; explainability and interpretability; multi and hyperspectral, optical and radar image processing; and so on.</li>
<li>Applications: Disaster relief; urban planning; sustainable and intelligent agriculture; coast, sea, and marine monitoring; pollution monitoring and air/water quality analysis; circular economy; Cultural Heritage documentation and preservation; climate change; sustainable development goals; geoscience; phenological studies; and so on.</li>
<br>
<br>
We are following the relatively recent trend in the field of machine learning that shifts the focus from improving machine learning models, also known as model-centric approaches, to optimizing the data used to train these models, including how this data is presented during the learning process. This shift has opened up a research direction known as data-centric machine learning.
<br>
<br>
To this end, we are combining this workshop with a data-centric machine learning challenge. Participants will be given an Earth observation data set, a task (such as segmentation), and a machine learning model. Their goal is to propose approaches that improve the quality of the training data to increase the overall performance on the test data. The best solutions will be selected based on the increase in performance on the test data. Creative and innovative approaches are especially encouraged. 
<br>
<br>
All the details on the challenge can be found on the official MVEO website.</p>

<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2161.544657596555!2d-2.2023420229653876!3d57.19611637990996!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x4884113d4bea3415%3A0x5dac74377f681031!2sNational%20Subsea%20Centre!5e0!3m2!1sen!2sus!4v1698418405363!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
</div></div>
</div></div>

<br>
<br>
<div class="col-12"><div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <div class="">
            <h4 class="pt-1 ">Artificial Intelligence and Computer Vision for Neurodegenerative Diseases Assessment: Advancing Computer Science in Dementia and Neurodegenerative Disorders (AI CV for NDS)</h4>
            <p class=" mb-1"><small>Friday, 24th November 2023</small></p>
             <p class=" mb-1"><small>Website: <a href="https://sites.google.com/view/ai-cv-for-nds" target="_blank">https://sites.google.com/view/ai-cv-for-nds</a></small></p>
            <p class=" mb-1"><small>Organisers: Donato Impedovo (University of Bari), Lerina Aversano (University of Sannio), Vincenzo Dentamaro (University of Bari Aldo Moro)</small></p>
            <p class=" mb-1"><small>Contact: vincenzo.dentamaro@uniba.it</small></p>
            <p class=" mb-1"><small>Venue: King's College, University of Aberdeen</small></p>
            <br>
            <p class="pb-2">We are delighted to host a pioneering workshop for the British Machine Vision Conference (BMVC) 2023, focusing on the latest advances in computer vision and behavioral biometrics applied to the assessment and understanding of neurodegenerative diseases. Neurodegenerative disorders, including Alzheimer's, Parkinson's, and Huntington's diseases, pose significant challenges to healthcare systems worldwide due to their progressive nature and the lack of effective treatment options. In recent years, AI-based approaches, particularly computer vision and behavioral biometrics, have shown promising results in early detection, diagnosis, and monitoring of these diseases, revolutionizing the way we approach neurodegenerative disorders.
<br>
<br>
This workshop aims to bring together researchers, clinicians, and industry professionals to discuss state-of-the-art techniques, share novel ideas, and establish new collaborations in the field of computer vision and behavioral biometrics applied to neurodegenerative diseases. The primary goal is to foster the development and integration of innovative AI solutions to improve the assessment and management of these debilitating conditions.
<br>
<br>
The workshop will cover a range of topics, including but not limited to:
<br>
<br>
1. Advanced computer vision techniques for analyzing medical imaging data, such as MRI, PET, and OCT, in neurodegenerative disorders.
<br>
2. Behavioral biometrics and gait analysis for early detection and diagnosis of neurodegenerative diseases.
<br>
3. Machine learning and deep learning algorithms for facial expression and emotion recognition in cognitive assessment.
<br>
4. Eye-tracking and pupillometry in monitoring disease progression and response to treatment.
<br>
5. Computer vision-based assessment of speech, voice, and language impairments in neurodegenerative diseases.
<br>
6. Integration of AI-driven computer vision and behavioral biometrics with wearable devices, IoT, and telemedicine for remote monitoring and management of patients.
<br>
7. Challenges and opportunities in data collection, annotation, and sharing for AI research in computer vision and behavioral biometrics applied to neurodegenerative diseases.
<br>
<br>
The workshop will feature invited keynote speakers, oral presentations, and poster sessions, providing ample opportunities for participants to engage in stimulating discussions and exchange ideas. We also plan to organize a panel discussion to address the challenges and future directions in the field of computer vision and behavioral biometrics applied to neurodegenerative diseases.
<br>
<br>
We firmly believe that this workshop will contribute to the advancement of knowledge and foster innovation in the application of computer vision and behavioral biometrics techniques to address the pressing challenges posed by neurodegenerative diseases, ultimately improving the quality of life for millions of patients and their families worldwide."
</p>
<iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe>
        </div>
    </div>
</div></div>
