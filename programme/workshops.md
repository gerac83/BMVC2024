---
layout: default_sparse
title: Workshops
permalink: /programme/workshops/
index: 15
---

<!-- <h4>From the 27th to 28th of November, 2024</h4> -->

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Workshop on Machine Vision for Earth Observation and Environment Monitoring</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://mveo.github.io/" target="_blank">https://mveo.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Keiller Nogueira, Lecturer, University of Liverpool; Jan Boehm, University College London; Fabiana Di Ciaccio, Assistant Professor, University of Florence; Ahmed Emam, PhD researcher, University of Bonn; Ronny Hänsch, German Aerospace Center (DLR); Chunbo Luo, University of Exeter; Diego Marcos, Junior Professor, Inria, Universite de Montpellier; Paolo Russo, Assistant Professor, Sapienza University of Rome.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> Keiller.Nogueira@liverpool.ac.uk</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The primary goal of this workshop is to foster collaboration and idea exchange between the Computer Vision, Remote Sensing, and Environmental Monitoring communities, both nationally and internationally. We aim to bring together researchers and experts from these  fields to promote interdisciplinary research, encourage innovative computer vision approaches for automated interpretation of Earth observation and Environmental data, and enhance knowledge within the Computer Vision community for this rapidly evolving and highly impactful area of research. The potential outcomes of this research are far-reaching, affecting human society, economy, industry, and the environment.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">The 2nd Workshop in Video Understanding and its Applications</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://vua-bmvc.github.io/2024/" target="_blank">https://vua-bmvc.github.io/2024/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Dr Faegheh Sardari, postdoctoral research fellow in Audio-Visual AI at the CVSSP, University of Surrey; Dr Armin Mustafa, lecturer in computer vision at the CVSSP, University of Surrey; Mr Asmar Nadeem, PhD student on multi-modal video understanding at the CVSSP, University of Surrey; Mr Davide Berghi, research engineer in audio-visual AI at the CVSSP, University of Surrey; Mr Robert Dawes, lead research engineer at the BBC; Prof. Adrian Hilton, full professor in computer vision and signal processing at the CVSSP, University of Surrey.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> f.sardari@surrey.ac.uk</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The proposed workshop brings together people working in the video understanding area in the Computer Vision and AI community, with the aim of discovering the general challenges and developing solutions in this area. Automatic analysis of the video plays an important role in many applications, such as video summarization, video highlights, and human action assessment. In our closing panel session, we will discuss the broader impact of video understanding in various real-world applications, which will enable the identification of future research challenges in the field.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m14!1m8!1m3!1d4324.360451543164!2d-2.191735!3d57.18525700000001!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48841376a7968181%3A0xb94af819aff77fdc!2sP%26J%20Live!5e0!3m2!1sen!2sus!4v1698417934220!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<!-- <h4>XXXX, XX November 2024</h4> -->

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1 ">Robust Recognition in the Open World</h4>
        <!-- <p class=" mb-1">XXXX, XX November 2024</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://rrow2024.github.io" target="_blank">https://rrow2024.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Hermann Blum, ETH Zürich; Hanno Gottschalk, TU Berlin; Kira Maag, TU Berlin; Matthias Rottmann, University of Wuppertal; Siniša Šegvić, University of Zagreb.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> rottmann@uni-wuppertal.de</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> This workshop addresses the challenges deep neural networks face with unexpected scenes and environments that differ from training data. We focus on methods and datasets to improve AI robustness and adaptability for critical applications like automated driving, robotics, and medical imaging.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">1st Workshop on Advancing Non-invasive Human Motion Characterization in the Clinical Domain: Methods and Applications</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://anima2024.sites.uu.nl/" target="_blank">https://anima2024.sites.uu.nl/</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Lucia Migliorelli, Postdoc, Department of Information Engineering, Marche Polytechnic University; Matteo Moro, Assistant Professor, Department of Informatics, Bioengineering, Robotics and Systems Engineering (DIBRIS),  University of Genova & Machine Learning Genoa (MaLGa) Center; Ronald Poppe, Associate Professor, Department of Information and Computing Sciences, Utrecht University.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> matteo.moro@unige.it</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Our workshop aims to contribute to the broader computer vision community by focusing on those challenges that are inherent, but not unique, to the medical domain. We believe that tackling these topics in behavioral motion analysis within the medical domain will not only advance healthcare technology but also push the boundaries of computer vision research. The workshop recruits high-quality and original research works focused on understanding human behaviour including, but not limited to:</p>
        <ul>
            <li>Motion quantification: measurement of human pose and motion in 2D or 3D.</li>
            <li>Motion classification: detection of specific human motions, training classifiers with limited data.</li>
            <li>Clinical datasets: dealing with data scarcity, privacy, federated learning, synthetic data, and benchmarking.</li>
            <li>Motion recording: use, calibration and combination of various sensors.</li>
            <li>Applications: in the domain of infant analysis, diagnostics and rehabilitation.</li>
            <li>Real-time analysis: algorithms to perform human motion analysis in real-time, enabling applications such as continuous monitoring in clinical settings.</li>
            <li class='text-justify'>Ethical considerations: studies that address ethical implications of using computer vision in healthcare, including issues related to privacy, consent and bias in algorithmic decision-making.</li>
        </ul>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2166.0768946863527!2d-2.1372157729696277!3d57.11864908597143!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x488411d39be0afc1%3A0x481d5954b6be4899!2sSir%20Ian%20Wood%20Building!5e0!3m2!1sen!2sus!4v1698418233408!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Media Authenticity in the Age of Artificial Intelligence</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://dbhowmik.github.io/MediaTrust/workshops/" target="_blank">https://dbhowmik.github.io/MediaTrust/workshops/</a></p>
        <p class=" mb-1"><b>Organisers:</b> Deepayan Bhowmik, Newcastle University, UK; Frederik Temmermans, Vrije Universiteit Brussel, Belgium; Sabrina Caldwell, Australian National University, Australia.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> deepayan.bhowmik@newcastle.ac.uk</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Recent advances in artificial intelligence, especially Generative AI, for media creation and manipulation enable users to produce near-realistic media content that is almost indistinguishable from authentic content to the human eye. These developments open a multitude of opportunities, from creative content production, the art industry, and digital restoration to image and video coding. However, they also risk infringing copyrights and spreading manipulated media, such as deepfakes, which often lead to social unrest, the spread of rumours for political gain, or the encouragement of hate crimes. The proposed workshop aims to solicit papers and talks addressing the current advances in trustworthy media generation, distribution and consumption. This includes but is not limited to, the use of machine learning / artificial intelligence in</p>
        <ul>
            <li>Generative AI and media trust</li>
            <li>Media privacy and security</li>
            <li>Media manipulation (including deepfake) detection</li>
            <li>AI-generated media content identification</li>
            <li>Media integrity, authenticity and provenance</li>
            <li>Initiatives to standardisation and policy</li>
            <li>Media authenticity use cases</li>
        </ul>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2161.544657596555!2d-2.2023420229653876!3d57.19611637990996!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x4884113d4bea3415%3A0x5dac74377f681031!2sNational%20Subsea%20Centre!5e0!3m2!1sen!2sus!4v1698418405363!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">DIFA: Deep Learning-based Image Fusion and Its Applications</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://difa2024.github.io/" target="_blank">https://difa2024.github.io</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Xingchen Zhang, Senior Lecturer, University of Exeter; Zhixiang Chen, Lecturer, University of Sheffield; Shuyan Li, Incomining lecturer at Queen's University Belfast; Yiannis Demiris, Professor, Imperial College London.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> x.zhang12@exeter.ac.uk</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Image fusion, with its expansive applications from surveillance and autonomous driving to medical diagnostics, has become a hot topic in recent years. Its relevance to the computer vision community is clear: as computer vision techniques evolve, the integration of varied image sources is crucial for pushing research boundaries. Beyond the computer vision community, the workshop holds wider appeal. Fields such as robotics, biometric recognition, medical image processing, and computational photography benefit from image fusion advancements. As the lines between traditional computer vision and these research fields blur, the discussions and insights from this workshop are positioned to inspire a broad spectrum of researchers and practitioners, emphasizing the value of interdisciplinary dialogue and collaboration.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Synthetic Realities and Biometric Security: Advances in Forensic Analysis and Threat Mitigation (SRBS)</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://sites.google.com/view/srbs-bmvc2024" target="_blank">https://sites.google.com/view/srbs-bmvc2024</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Naser Damer, Senior Research Fellow, Fraunhofer Institute for Computer Graphics Research IGD, Germany; Marija Ivanovska, Assistant, University of Ljubljana; Vishal Patel, Associate Professor, Johns Hopkins University; Ajita Rattani, University of North Texas; Anderson Rocha, Full Professor, University of Campinas; Vitomir Štruc, Full Professor, University of Ljubljana, Slovenia.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> marija.ivanovska@fe.uni-lj.si</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> Recent advancements in deep learning algorithms, such as Generative Adversarial Networks (GANs) and Diffusion models, have led to a surge in the creation of highly realistic images and videos, which are often indistinguishable from genuine content to the human eye. While these developments have benefited the entertainment industry, they are often used to spread misinformation and manipulate public opinion. Moreover, in the security domain, synthetic and manipulated images and videos are frequently utilized to impersonate individuals, enabling unauthorized parties to bypass systems for biometric authentication gaining illegal access to sensitive information. Accurate detection of fake data is crucial for preventing security breaches and safeguarding the integrity of security measures and public information.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>

---

<div class="row pt-2 pb-2 align-items-center">
    <div class="col-12 col-md-12 col-lg-12">
        <h4 class="pt-1">Privacy, Fairness, Accountability and Transparency in Computer Vision</h4>
        <!-- <p class=" mb-1"><b>Date:</b> TBC</p> -->
        <p class=" mb-1"><b>Website:</b> <a href="https://sites.google.com/view/pfatcvbmvc24/home" target="_blank">https://sites.google.com/view/pfatcvbmvc24/home</a></p>
        <p class=" mb-1 text-justify"><b>Organisers:</b> Dr. Fani Deligianni, University of Glasgow; Dr. Idris Zakariyya, University of Glasgow; Dr. Ng Pai Chet, Singapore Institute of Technology; Prof. Mubarak Shah, Center for Research in Computer Vision, University of Central Florida.</p>
        <!-- <p class=" mb-1"><b>Contact:</b> fani.deligianni@glasgow.ac.uk</p> -->
        <p class=" mb-1"><b>Venue:</b> Scottish Exhibition Centre, Glasgow.</p>
        <p class="pb-1 text-justify"><b>Summary:</b> The advances in computer vision research have transformed the way people work and think. Deep learning techniques has outperformed classical machine learning and exceeded human performance, demonstrating the potential to translate computer vision in critical real applications. Nevertheless, applying these techniques broadly in privacy sensitive domains is met with significant hurdles, including ethical considerations, safety, and privacy issues, all of which must be thoroughly considered and resolved prior to widespread adoption. Furthermore, the ethical consideration of employing these technologies to continuous monitoring has been underestimated, since signatures of biometrics can be revealed even when subjects are not directly identifiable. This workshop invites outstanding works on this technically challenging domain to reveal threats and ethical issues and propose solutions.</p>
        <!-- <iframe src="https://www.google.com/maps/embed?pb=!1m18!1m12!1m3!1d2163.4319531046876!2d-2.1041544229671674!3d57.16386598243411!2m3!1f0!2f0!3f0!3m2!1i1024!2i768!4f13.1!3m3!1m2!1s0x48840e0feaf19727%3A0xeea5297ff532400a!2sKing&#39;s%20College!5e0!3m2!1sen!2sus!4v1698418531882!5m2!1sen!2sus" width="400" height="300" style="border:0;" allowfullscreen="" loading="lazy" referrerpolicy="no-referrer-when-downgrade"></iframe> -->
    </div>
</div>
